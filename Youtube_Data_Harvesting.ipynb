{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pymongo\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SzKUj8WQQOQS"
      },
      "outputs": [],
      "source": [
        "api_id=\"AIzaSyAVQe1FRchb2efA0N7H_zbN6kqLTQVxNEg\"\n",
        "api_service_name=\"youtube\"\n",
        "api_version=\"v3\"\n",
        "youtube=build(api_service_name,api_version,developerKey=api_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JlBR-gSBQOTi"
      },
      "outputs": [],
      "source": [
        "#to get channel details\n",
        "def channel_data(ch_id):\n",
        "  ch=[]\n",
        "  request = youtube.channels().list(\n",
        "        part=\"snippet,contentDetails,statistics\",\n",
        "        id=ch_id\n",
        "    )\n",
        "  response = request.execute()\n",
        "  for i in response['items']:\n",
        "    ch_data = {\n",
        "        'Channel_name':i['snippet']['title'],\n",
        "        'Channel_ID':i['id'],\n",
        "        'Subscription_Count': i['statistics']['subscriberCount'],\n",
        "        'Channel_Views':i['statistics']['viewCount'],\n",
        "        'Total_videos':i['statistics']['videoCount'],\n",
        "        'Channel_Description':i['snippet']['description'],\n",
        "        'Playlist_ID':i['contentDetails']['relatedPlaylists']['uploads']\n",
        "    }\n",
        "    ch.append(ch_data)\n",
        "  return ch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSF_7tRa9vqy",
        "outputId": "80b1b549-5693-4cdf-8b24-5071f3bfca57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'Channel_name': 'Ellen and Brian',\n",
              "  'Channel_ID': 'UCVHBHVFSblwTROo5d9uShZg',\n",
              "  'Subscription_Count': '3340000',\n",
              "  'Channel_Views': '648341412',\n",
              "  'Total_videos': '373',\n",
              "  'Channel_Description': 'Hi! We are a husband-and-wife duo specializing in K-pop dance covers, dance tutorials, fashion, and lifestyle content. We love to share our passion through our videos, which have amassed over 1 billion views across various social media channels. Together, we have collaborated and danced with numerous K-pop artists, such as Chung Ha, NMIXX, AB6IX, Yoo Jung from Weki Meki, LIGHTSUM, and more.\\n\\nBusiness/Partnerships email:  \\nellenandbrian28@gmail.com',\n",
              "  'Playlist_ID': 'UUVHBHVFSblwTROo5d9uShZg'}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "channel=channel_data(\"UCVHBHVFSblwTROo5d9uShZg\")\n",
        "channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "44wqT6szgSia"
      },
      "outputs": [],
      "source": [
        "#to get the video id's using the playlist id\n",
        "def video_id(channel_id):\n",
        "  video_ids=[]\n",
        "  next_page_token=None\n",
        "  #to get playlist id\n",
        "  request=youtube.channels().list(\n",
        "    part=\"contentDetails\",\n",
        "    id=channel_id\n",
        ")\n",
        "  response=request.execute()\n",
        "  playlist_id=response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "  playlist_id\n",
        "  while (True):\n",
        "    request1=youtube.playlistItems().list(\n",
        "        part=\"snippet\",\n",
        "        playlistId=playlist_id,\n",
        "        maxResults=50,\n",
        "        pageToken=next_page_token\n",
        "    )\n",
        "    response1=request1.execute()\n",
        "\n",
        "    for i in range(len(response1['items'])):\n",
        "      v_id=response1['items'][0]['snippet']['resourceId']['videoId']\n",
        "      video_ids.append(v_id)\n",
        "    next_page_token=response1.get('nextPageToken')\n",
        "\n",
        "    if next_page_token is None:\n",
        "      break\n",
        "\n",
        "  return video_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_KHBsKbXaC5",
        "outputId": "32030282-ff1a-4b69-e860-ded03c70c7bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'gW0ke2NoQvg', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'lKluxlGQO-c', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'rV1oiuU5U80', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'Jq0KHDdlOTk', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'X4PkYs_j1iM', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', 'Pq5yVHMcM9w', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', '7EmdBSQoor0', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ', 'MltvSqw5cLQ']\n"
          ]
        }
      ],
      "source": [
        "v=video_id(\"UCVHBHVFSblwTROo5d9uShZg\")\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xx3QDifhB7Up"
      },
      "outputs": [],
      "source": [
        "#to get video details\n",
        "def video_details(video_ids):\n",
        "  V=[]\n",
        "  for video in video_ids:\n",
        "     request = youtube.videos().list(\n",
        "         part='snippet,contentDetails,statistics',\n",
        "         id=video\n",
        "      )\n",
        "     response = request.execute()\n",
        "     for i in response['items']:\n",
        "        video_data={\n",
        "            \"Channel_name\":i['snippet']['channelTitle'],\n",
        "            \"Channel_ID\":i['snippet']['channelId'],\n",
        "            \"Video_Id\":i['id'] ,\n",
        "            \"Title\":i['snippet']['title'],\n",
        "            \"Video_Description\":i['snippet'].get('description') ,\n",
        "            \"Tags\":i['snippet'].get('tags'),\n",
        "            \"PublishedAt\":i['snippet']['publishedAt'] ,\n",
        "            \"View_Count\":i['statistics']['viewCount'] ,\n",
        "            \"Like_Count\":i['statistics']['likeCount'],\n",
        "            \"Favorite_Count\":i['statistics']['favoriteCount'],\n",
        "            \"Comment_Count\":i['statistics'].get('commentCount') ,\n",
        "            \"Duration\":i['contentDetails']['duration'] ,\n",
        "            \"Thumbnail\":i['snippet']['thumbnails']['default'].get('url'),\n",
        "            \"Definition\":i['contentDetails']['definition'],\n",
        "            \"Caption_Status\":i['contentDetails']['caption']\n",
        "          }\n",
        "        V.append(video_data)\n",
        "  return V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ao634mXjCyUc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'v' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m video\u001b[38;5;241m=\u001b[39mvideo_details(\u001b[43mv\u001b[49m)\n\u001b[0;32m      2\u001b[0m video\n",
            "\u001b[1;31mNameError\u001b[0m: name 'v' is not defined"
          ]
        }
      ],
      "source": [
        "video=video_details(v)\n",
        "video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_ekqpSS3DPaP"
      },
      "outputs": [],
      "source": [
        "#to get comment details\n",
        "def comment_details(v):\n",
        "  c=[]\n",
        "  try:\n",
        "    for i in v:\n",
        "      request = youtube.commentThreads().list(\n",
        "          part='snippet,replies',\n",
        "          videoId=i,\n",
        "          maxResults=50\n",
        "      )\n",
        "      response = request.execute()\n",
        "      for j in response['items']:\n",
        "        comment_data={\n",
        "          \"Comment_Id\":j['id'],\n",
        "          \"Video_Id\":j['snippet']['videoId'],\n",
        "          \"Comment_Text\":j['snippet']['topLevelComment']['snippet']['textDisplay'] ,\n",
        "          \"Comment_Author\":j['snippet']['topLevelComment']['snippet']['authorDisplayName'] ,\n",
        "          \"Comment_PublishedAt\":j['snippet']['topLevelComment']['snippet']['publishedAt']\n",
        "\n",
        "        }\n",
        "        c.append(comment_data)\n",
        "  except:\n",
        "    pass\n",
        "  return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PZNkXuOx7Ia",
        "outputId": "7b7416a6-52c3-47cd-d5d4-d9d0fa594cc2"
      },
      "outputs": [],
      "source": [
        "comment_details(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_Ceg3XnLEzy9"
      },
      "outputs": [],
      "source": [
        "conn=pymongo.MongoClient(\"mongodb://Revathy:guvi2024@ac-5n8fsfk-shard-00-00.berjwr1.mongodb.net:27017,ac-5n8fsfk-shard-00-01.berjwr1.mongodb.net:27017,ac-5n8fsfk-shard-00-02.berjwr1.mongodb.net:27017/?ssl=true&replicaSet=atlas-11ihco-shard-0&authSource=admin&retryWrites=true&w=majority&appName=Cluster0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L2rt8QUXJpoc"
      },
      "outputs": [],
      "source": [
        "db=conn[\"youtube\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3tS300VGIh8T"
      },
      "outputs": [],
      "source": [
        "def channel_details(channel_id):\n",
        "  ch_info=channel_data(channel_id)\n",
        "  v_id=video_id(channel_id)\n",
        "  v_details=video_details(v)\n",
        "  c_details=comment_details(v)\n",
        "  coll=db[\"youtube_data\"]\n",
        "  coll.insert_one({\"Channel_info\":ch_info,\"Video IDs\":v_id,\"Video Details\":v_details,\"Comment Info\":c_details})\n",
        "\n",
        "  return \"Data uploaded successfully\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7aurhWhYKoEo",
        "outputId": "c3f226bb-128f-40e0-89bd-173bbc0fc581"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Data uploaded successfully'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "channel_details(\"UCVHBHVFSblwTROo5d9uShZg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Record inserted successfully!\n",
            "Record inserted successfully!\n",
            "Record inserted successfully!\n"
          ]
        }
      ],
      "source": [
        "#creating tables\n",
        "def channel_table():\n",
        "    #importing\n",
        " import psycopg2\n",
        "\n",
        "# Establish a connection to your MySQL database\n",
        "mydb = psycopg2.connect(\n",
        "    host=\"localhost\",\n",
        "    user=\"postgres\",\n",
        "    password=\"Revathy@27\",\n",
        "    database=\"Youtube\"\n",
        ")\n",
        "\n",
        "# Create a cursor object\n",
        "mycursor = mydb.cursor()\n",
        "drop_query='''drop table if exists channels'''\n",
        "mycursor.execute(drop_query)\n",
        "mydb.commit()\n",
        "try:\n",
        "    # Define the CREATE TABLE query\n",
        "    create_query = '''\n",
        "        CREATE TABLE IF NOT EXISTS channels (\n",
        "            channel_name VARCHAR(100),\n",
        "            channel_ID VARCHAR(80) PRIMARY KEY,\n",
        "            total_view BIGINT,\n",
        "            total_subscribers BIGINT,\n",
        "            total_videos INT,\n",
        "            channel_description TEXT,\n",
        "            playlist_id VARCHAR(80)\n",
        "        )\n",
        "    '''\n",
        "\n",
        "    # Execute the query\n",
        "    mycursor.execute(create_query)\n",
        "# Commit the changes\n",
        "    mydb.commit()\n",
        "except:\n",
        "    print(\"Table already exist\")\n",
        "\n",
        "#Extracting data from MongoDB\n",
        "ch_list=[]\n",
        "db=conn['youtube']\n",
        "coll=db[\"youtube_data\"]\n",
        "for ch_d in coll.find({},{\"_id\":0,\"Channel_info\":1}):\n",
        "    for i in  range(len(ch_d['Channel_info'])):\n",
        "        ch_list.append(ch_d['Channel_info'][i])\n",
        "#Making the extracted data as dataframe\n",
        "df=pd.DataFrame(ch_list)\n",
        "\n",
        "#Mapping with postgeral\n",
        "for i,row in df.iterrows():\n",
        "    #print(i,row)\n",
        "    insert_query='''insert into channels(channel_name,\n",
        "                                        channel_id,\n",
        "                                        total_view,\n",
        "                                        total_subscribers,\n",
        "                                        total_videos,\n",
        "                                        channel_description,\n",
        "                                        playlist_id)\n",
        "                                        values(%s,%s,%s,%s,%s,%s,%s)'''\n",
        "    values=(row['channel_name'],\n",
        "            row['Channel_ID'],\n",
        "            row['Subscription_Count'],\n",
        "            row['Channel_Views'],\n",
        "            row['Total_videos'],\n",
        "            row['Channel_Description'],\n",
        "            row['Playlist_ID'])\n",
        "# Connect to your database and execute the query\n",
        "    try:\n",
        "        mycursor.execute(insert_query,values)\n",
        "        mydb.commit()\n",
        "        print(\"Record inserted successfully!\")\n",
        "    except:\n",
        "        print(\"Record already inserted\")\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Video Table\n",
        "def video_table():\n",
        "      import psycopg2\n",
        "# Establish a connection to your MySQL database\n",
        "mydb = psycopg2.connect(\n",
        "                host=\"localhost\",\n",
        "                user=\"postgres\",\n",
        "                password=\"Revathy@27\",\n",
        "                database=\"Youtube\"\n",
        "        )\n",
        "\n",
        "        # Create a cursor object\n",
        "mycursor = mydb.cursor()\n",
        "drop_query='''drop table if exists videos'''\n",
        "mycursor.execute(drop_query)\n",
        "mydb.commit()\n",
        "try:\n",
        "                # Define the CREATE TABLE query\n",
        "        create_query = '''\n",
        "        CREATE TABLE IF NOT EXISTS videos (Channel_name varchar(100),\n",
        "                                                        Channel_ID varchar(100),\n",
        "                                                        Video_ID varchar(100) primary key,\n",
        "                                                        Title varchar(150),\n",
        "                                                        Tags text,\n",
        "                                                        Thumbnails varchar(200),\n",
        "                                                        Description text,\n",
        "                                                        Published_Date timestamp,\n",
        "                                                        Duration interval,\n",
        "                                                        Video_Views bigint,\n",
        "                                                        video_likes bigint,\n",
        "                                                        Video_Comments int,\n",
        "                                                        Favourite_count int,\n",
        "                                                        Definition varchar(100),\n",
        "                                                        Caption_Status varchar(100))\n",
        "\n",
        "        '''\n",
        "        \n",
        "        # Execute the query\n",
        "        mycursor.execute(create_query)\n",
        "\n",
        "        # Commit the changes\n",
        "        mydb.commit()\n",
        "\n",
        "except:\n",
        "        print(\"Table already exist\")\n",
        "\n",
        "#Extracting data from MongoDB\n",
        "vi_list=[]\n",
        "db=conn[\"youtube\"]\n",
        "coll=db[\"youtube_data\"]\n",
        "for vi_d in coll.find({},{\"_id\":0,\"Video Details\":1}):\n",
        "        for i in range(len(vi_d['Video Details'])):\n",
        "            vi_list.append(vi_d['Video Details'][i])\n",
        "    #Making the extracted data as dataframe\n",
        "df2=pd.DataFrame(vi_list)\n",
        "\n",
        "\n",
        "    #Mapping with postgeral\n",
        "for i,row in df2.iterrows():\n",
        "        #print(i,row)\n",
        "        insert_query='''insert into videos (Channel_name,\n",
        "                                            Channel_ID,\n",
        "                                            Video_Id,\n",
        "                                            Title,\n",
        "                                            Tags,\n",
        "                                            Thumbnail,\n",
        "                                            Video_Description,\n",
        "                                            PublishedAt,\n",
        "                                            Duration,\n",
        "                                            View_Count,\n",
        "                                            Like_Count ,\n",
        "                                            Comment_Count,\n",
        "                                            Favorite_Count,\n",
        "                                            Definition,\n",
        "                                            Caption_Status   \n",
        "                                            )\n",
        "                                            values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'''\n",
        "        values=(row['Channel_name'],\n",
        "                row['Channel_ID'],\n",
        "                row['Video_Id'],\n",
        "                row['Title'],\n",
        "                row['Tags'],\n",
        "                row['Thumbnail'],\n",
        "                row['Video_Description'],\n",
        "                row['PublishedAt'],\n",
        "                row['Duration'],\n",
        "                row['View_Count'],\n",
        "                row['Like_Count'],\n",
        "                row['Comment_Count'],\n",
        "                row['Favorite_Count'],\n",
        "                row['Definition'],\n",
        "                row['Caption_Status']\n",
        "                )\n",
        "        try:\n",
        "            #Connect to your database and execute the query\n",
        "            mycursor.execute(insert_query,values)\n",
        "            mydb.commit()\n",
        "            print(\"Video_Record inserted successfully!\")\n",
        "        except:\n",
        "            print(\"Video_record already inserted\")\n",
        "        \n",
        "video_table()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comment_table():\n",
        "    #Comment Table\n",
        "    # Establish a connection to your MySQL database\n",
        "    mydb = psycopg2.connect(\n",
        "        host=\"localhost\",\n",
        "        user=\"postgres\",\n",
        "        password=\"Revathy@27\",\n",
        "        database=\"Youtube\"\n",
        "    )\n",
        "\n",
        "    # Create a cursor object\n",
        "    mycursor = mydb.cursor()\n",
        "    drop_query='''drop table if exists comments'''\n",
        "    mycursor.execute(drop_query)\n",
        "    mydb.commit()\n",
        "    try:\n",
        "        # Define the CREATE TABLE query\n",
        "        create_query = '''\n",
        "            CREATE TABLE IF NOT EXISTS comments(comment_id varchar(100) primary key,\n",
        "                                                video_id varchar(100),\n",
        "                                                comment_text text,\n",
        "                                                comment_author varchar(100) ,\n",
        "                                                comment_published_date timestamp\n",
        "                                                    \n",
        "            )\n",
        "        '''\n",
        "\n",
        "        # Execute the query\n",
        "        mycursor.execute(create_query)\n",
        "\n",
        "        # Commit the changes\n",
        "        mydb.commit()\n",
        "    except:\n",
        "        print(\"Table already exist\")\n",
        "\n",
        "#Extracting data from MongoDB\n",
        "com_list=[]\n",
        "db=conn[\"youtube\"]\n",
        "coll=db[\"youtube_data\"]\n",
        "for com_d in coll.find({},{\"_id\":0,'Comment Info':1}):\n",
        "        for i in range(len(com_d['Comment Info'])):\n",
        "            com_list.append(com_d['Comment Info'][i])\n",
        "    #Making the extracted data as dataframe\n",
        "df3=pd.DataFrame(com_list)\n",
        "\n",
        "\n",
        "    #Mapping with postgeral\n",
        "for i,row in df3.iterrows():\n",
        "        #print(i,row)\n",
        "        insert_query='''insert into comments(Comment_Id,\n",
        "                                            Video_Id,\n",
        "                                            Comment_Text,\n",
        "                                            Comment_Author,\n",
        "                                            Comment_PublishedAt\n",
        "                                            )\n",
        "                                            values(%s,%s,%s,%s,%s)'''\n",
        "        values=(row['Comment_Id'],\n",
        "                row['Video_Id'],\n",
        "                row['Comment_Text'],\n",
        "                row['Comment_Author'],\n",
        "                row['Comment_PublishedAt'])\n",
        "        \n",
        "        try:\n",
        "            mycursor.execute(insert_query,values)\n",
        "            mydb.commit()\n",
        "            print(\"Comment_Record inserted successfully!\")\n",
        "        except:\n",
        "            print(\"Comment_Record already inserted\")\n",
        "\n",
        "comment_table()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "  #Defining function for all tables\n",
        "def tables():\n",
        "    channel_table()\n",
        "    video_table()\n",
        "    comment_table()\n",
        "    return 'Table created and Migrated to SQL Database'\n",
        "         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_channels_tables():\n",
        "    #Extracting data from MongoDB\n",
        "    ch_list=[]\n",
        "    db=conn['youtube']\n",
        "    coll=db[\"youtube_data\"]\n",
        "    for ch_d in coll.find({},{\"_id\":0,\"Channel_info\":1}):\n",
        "        for i in  range(len(ch_d['Channel_info'])):\n",
        "            ch_list.append(ch_d['Channel_info'][i])\n",
        "    #Making the extracted data as dataframe\n",
        "    df = st.DataFrame(ch_list)\n",
        "    \n",
        "\n",
        "def show_videos_tables():\n",
        "    #Extracting data from MongoDB\n",
        "    vi_list=[]\n",
        "    db=conn[\"youtube\"]\n",
        "    coll=db[\"youtube_data\"]\n",
        "    for vi_d in coll.find({},{\"_id\":0,\"Video Details\":1}):\n",
        "            for i in range(len(vi_d['Video Details'])):\n",
        "                vi_list.append(vi_d['Video Details'][i])\n",
        "        #Making the extracted data as dataframe\n",
        "    df2=st.DataFrame(vi_list)\n",
        "    \n",
        "\n",
        "def show_comment_tables():\n",
        "     #Extracting data from MongoDB\n",
        "    com_list=[]\n",
        "    db=conn[\"youtube\"]\n",
        "    coll=db[\"youtube_data\"]\n",
        "    for com_d in coll.find({},{\"_id\":0,'Comment Info':1}):\n",
        "            for i in range(len(com_d['Comment Info'])):\n",
        "                com_list.append(com_d['Comment Info'][i])\n",
        "        #Making the extracted data as dataframe\n",
        "    df3=st.DataFrame(com_list)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "ename": "UndefinedColumn",
          "evalue": "column \"title\" does not exist\nLINE 1:  select Title as Video_name,Channel_name from videos\n                ^\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[71], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Questions\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.Name of all the videos and their corresponding channels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     60\u001b[0m     query1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m select Title as Video_name,Channel_name from videos\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mmycursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     mydb\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     63\u001b[0m     t1\u001b[38;5;241m=\u001b[39mmycursor\u001b[38;5;241m.\u001b[39mfetchall()\n",
            "\u001b[1;31mUndefinedColumn\u001b[0m: column \"title\" does not exist\nLINE 1:  select Title as Video_name,Channel_name from videos\n                ^\n"
          ]
        }
      ],
      "source": [
        "#Streamlit Part\n",
        "st.title(\":purple[Youtube Data Harvesting and warehousing]\")\n",
        "\n",
        "#Get_User_input\n",
        "channel_ID=st.text_input(\"Enter the Channel_ID:\")\n",
        "\n",
        "#Store to mongoDB database\n",
        "store_Data=st.button(\"Collect and store Data\")\n",
        "if store_Data:\n",
        "    ch_ids=[]\n",
        "    db=conn[\"youtube\"]\n",
        "    coll=db[\"youtube_data\"]\n",
        "    for ch_data in coll.find({},{\"_id\":0,\"Channel_Information\":1}):\n",
        "        ch_ids.append(ch_data[\"Channel_Information\"]['Channel_ID'])\n",
        "    if channel_ID in ch_ids:\n",
        "        st.error(\"The given channel detail already exist in Database\")\n",
        "    else:\n",
        "        inserted=channel_details(channel_ID)\n",
        "        st.success(\"Succesfully installed\")\n",
        "\n",
        "#Migrate to SQL\n",
        "SQL=st.button(\"Migrate to SQL\")\n",
        "if SQL:\n",
        "    Tables=tables()\n",
        "    st.success(Tables)\n",
        "\n",
        "#Displaying table for viewing\n",
        "show_tables=st.radio(\"Select the table for view\",(\"channels\",\"playlists\",\"videos\",\"comments\"))\n",
        "if show_tables == \"channels\":\n",
        "    show_channels_tables()\n",
        "elif show_tables == \"videos\":\n",
        "    show_videos_tables()\n",
        "elif show_tables == \"comments\":\n",
        "    show_comment_tables()\n",
        "\n",
        "#SQL_Query\n",
        "Questions=st.selectbox(\"Select your Question\",(\n",
        "                                              \"1.Name of all the videos and their corresponding channels\",\n",
        "                                              \"2.Channel that have most number of videos and the count of the videos\",\n",
        "                                              \"3.Top 10 viewed videos and their corresponding channels\",\n",
        "                                              \"4.Total number of comment on each video and their respective video name\",\n",
        "                                              \"5.Videos that have the highest number of likes and their corresponding channel name\",\n",
        "                                              \"6.Total number of likes and dislikes on each video and their corresponding video name\",\n",
        "                                              \"7.Total number of views for each channel and their respective channel name \",\n",
        "                                              \"8.Names of all the channel that have published video in the year 2022\",\n",
        "                                              \"9.Average duration of all videos in each channel and their corresponding channel name\",\n",
        "                                              \"10.Videos having highest number of comments and their corresponding channel name\"\n",
        "\n",
        "))\n",
        "\n",
        "mydb = psycopg2.connect(\n",
        "        host=\"localhost\",\n",
        "        user=\"postgres\",\n",
        "        password=\"Revathy@27\",\n",
        "        database=\"Youtube\"\n",
        "    )\n",
        "mycursor = mydb.cursor()\n",
        "\n",
        "if Questions==\"1.Name of all the videos and their corresponding channels\":\n",
        "    query1=''' select Title as Video_name,Channel_name from videos'''\n",
        "    mycursor.execute(query1)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df=pd.DataFrame(t1,columns=[\"Video_name\",\"Channel_name\"])\n",
        "    st.write(df)\n",
        "elif Questions==\"2.Channel that have most number of videos and the count of the videos\":\n",
        "    query2=''' select channel_name, total_videos from channels order by total_videos desc'''\n",
        "    mycursor.execute(query2)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df2=pd.DataFrame(t1,columns=[\"channel_name\",\"total_videos\"])\n",
        "    st.write(df2)\n",
        "elif Questions==\"3.Top 10 viewed videos and their corresponding channels\":\n",
        "    query3=''' select title,video_views from videos order by video_views desc limit 10'''\n",
        "    mycursor.execute(query3)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df3=pd.DataFrame(t1,columns=[\"Video_title\",\"Video_views\"])\n",
        "    st.write(df3)\n",
        "elif Questions==\"4.Total number of comment on each video and their respective video name\":\n",
        "    query4=''' select title,video_comments from videos'''\n",
        "    mycursor.execute(query4)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df4=pd.DataFrame(t1,columns=[\"Video_title\",\"Video_comments\"])\n",
        "    st.write(df4)\n",
        "elif  Questions==\"5.Videos that have the highest number of likes and their corresponding channel name\":\n",
        "    query5=''' select title,video_likes from videos where video_likes is not null order by video_likes desc'''\n",
        "    mycursor.execute(query5)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df5=pd.DataFrame(t1,columns=[\"Video_title\",\"Video_likes\"])\n",
        "    st.write(df5) \n",
        "elif  Questions==\"6.Total number of likes and dislikes on each video and their corresponding video name\":\n",
        "    query6=''' select title,video_likes from videos '''\n",
        "    mycursor.execute(query6)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df6=pd.DataFrame(t1,columns=[\"Video_title\",\"Video_likes\"])\n",
        "    st.write(df6) \n",
        "elif Questions==\"7.Total number of views for each channel and their respective channel name \":\n",
        "    query7=''' select channel_name,total_view from channels '''\n",
        "    mycursor.execute(query7)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df7=pd.DataFrame(t1,columns=[\"Channel_name\",\"Total_view\"])\n",
        "    st.write(df7)  \n",
        "elif Questions==\"8.Names of all the channel that have published video in the year 2022\":\n",
        "    query8='''select title,channel_name,published_date from videos where extract(year from published_date)=2022'''\n",
        "    mycursor.execute(query8)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df8=pd.DataFrame(t1,columns=[\"Channel_name\",\"Year_Published\",\"Title\"])\n",
        "    st.write(df8)  \n",
        "elif Questions==\"9.Average duration of all videos in each channel and their corresponding channel name\":\n",
        "    query9='''select channel_name,AVG(duration) as avg_duration from videos group by channel_name'''\n",
        "    mycursor.execute(query9)\n",
        "    mydb.commit()\n",
        "    t1=mycursor.fetchall()\n",
        "    df9=pd.DataFrame(t1,columns=[\"Channel_name\",\"Avg_Duration\"])\n",
        "    t9=[]\n",
        "    for ind,row in df9.iterrows():\n",
        "        channel_title=row[\"Channel_name\"]\n",
        "        channel_avg_duration=row[\"Avg_Duration\"]\n",
        "        channel_avg_duration_str=str(channel_avg_duration)\n",
        "        t9.append({\"Channel_name\":channel_title,\"Channel_Avg_Duration\":channel_avg_duration_str})\n",
        "    df=pd.DataFrame(t9)\n",
        "    st.write(df)  \n",
        "elif  Questions==\"10.Videos having highest number of comments and their corresponding channel name\":\n",
        "    query10='''select title,channel_name,video_comments from videos where video_comments is not null order by video_comments  desc'''\n",
        "    mycursor.execute(query10)\n",
        "    mydb.commit()\n",
        "    t10=mycursor.fetchall()\n",
        "    df10=pd.DataFrame(t10,columns=[\"Channel_name\",\"Title\",\"video_comments\"])\n",
        "    st.write(df10)  \n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "     \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
